{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations\n",
    "<br> I install modules that I need and do not yet exist in my python environment using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webdriver-manager\n",
    "# !pip install selenium==4.11.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import string\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search term\n",
    "search_term = \"crypto.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I start an automated session where the driver will open a browser and input my credentials to log into my twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start selenium driver\n",
    "options = webdriver.ChromeOptions()\n",
    "header = {'User-agent': 'ep 0.1.2'}\n",
    "options.add_argument('--headless')  # runs browser in headless mode\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--log-level=3')\n",
    "options.add_argument('--disable-notifications')\n",
    "options.add_argument('--disable-popup-blocking')\n",
    "options.add_argument('--user-agent={}'.format(header))\n",
    "options.add_experimental_option(\n",
    "    \"excludeSwitches\", [\"enable-automation\"],\n",
    ")\n",
    "prefs = {\n",
    "    \"credentials_enable_service\": False,\n",
    "    \"profile.password_manager_enabled\": False,\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# driver = webdriver.Chrome(executable_path=ChromeDriverManager().install(),\n",
    "#                         options= options, )\n",
    "# driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(options = options)\n",
    "driver.maximize_window() \n",
    "url = u'https://twitter.com/search?q=%40'+search_term+'&src=typed_query&f=live'\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "# key in username\n",
    "username = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[5]/label/div/div[2]/div/input')))\n",
    "username.click()\n",
    "username.send_keys(\"xx\") #replace with your username\n",
    "\n",
    "# click next\n",
    "next_button = driver.find_element(By.XPATH,\"//span[contains(text(),'Next')]\")\n",
    "next_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# key in pw\n",
    "pw = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[3]/div/label/div/div[2]/div[1]/input')))\n",
    "pw.click()\n",
    "pw.send_keys(\"xx\") #replace with your pw\n",
    "\n",
    "# click log in\n",
    "login_button = driver.find_element(By.XPATH,\"//span[contains(text(),'Log in')]\")\n",
    "login_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# #key in search term\n",
    "# search_box = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div[2]/div/div[2]/div/div/div/div[1]/div/div/div/form/div[1]/div/div/div/label/div[2]/div/input')))\n",
    "# search_box.click()\n",
    "# search_box.send_keys(\"@kris\")\n",
    "# search_box.send_keys(Keys.ENTER)\n",
    "# time.sleep(3)\n",
    "\n",
    "# #navigate to live \n",
    "# latest = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div[1]/div/div[1]/div[1]/div[2]/nav/div/div[2]/div/div[2]/a')))\n",
    "# latest.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwhich the driver will scroll and copy the information we want to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful for Noah Williams\n",
      "@Naohwilliams01\n",
      "·\n",
      "7m\n",
      "Successful for Noah Williams\n",
      "@Naohwilliams01\n",
      "·\n",
      "7m\n",
      "Successful for Crypto.com Customer Support\n",
      "@cryptocomcs\n",
      "·\n",
      "34m\n",
      "Successful for Crypto.com\n",
      "@cryptocom\n",
      "·\n",
      "2h\n",
      "Successful for Crypto.com\n",
      "@cryptocom\n",
      "·\n",
      "2h\n",
      "Successful for b s $GEKKO is now on Crypto.com\n",
      "@BaniSamadani\n",
      "·\n",
      "2h\n",
      "Successful for b s $GEKKO is now on Crypto.com\n",
      "@BaniSamadani\n",
      "·\n",
      "3h\n",
      "Successful for GalihPradanaEvilKongsNFTs\n",
      "@GalihPradana34\n",
      "·\n",
      "4h\n",
      "Successful for GalihPradanaEvilKongsNFTs\n",
      "@GalihPradana34\n",
      "·\n",
      "4h\n",
      "Successful for Paul Riley Amanda\n",
      "@makayla83209\n",
      "·\n",
      "4h\n",
      "Successful for Crypto.com Kings.cro\n",
      "@ErikCou3993772\n",
      "·\n",
      "5h\n",
      "Successful for Crypto.com\n",
      "@cryptocom_AU\n",
      "·\n",
      "6h\n",
      "Successful for b s $GEKKO is now on Crypto.com\n",
      "@BaniSamadani\n",
      "·\n",
      "6h\n",
      "Successful for WildBoiCrypto\n",
      "@17Wildboi\n",
      "·\n",
      "8h\n",
      "Successful for NeyomY $GEKKO is now on Crypto.com\n",
      "@YNeyom\n",
      "·\n",
      "8h\n",
      "Successful for NeyomY $GEKKO is now on Crypto.com\n",
      "@YNeyom\n",
      "·\n",
      "9h\n",
      "Successful for Dutch Crypto Hodler\n",
      "@DutchCryptoCom\n",
      "·\n",
      "10h\n",
      "Successful for Crypto.com\n",
      "@cryptocom\n",
      "·\n",
      "10h\n",
      "Successful for Saurabh singh| $GEKKO is now on crypto.com\n",
      "@saurrabhhhh\n",
      "·\n",
      "11h\n",
      "Successful for Lakers Türkiye\n",
      "@LakersTRK\n",
      "·\n",
      "11h\n",
      "Successful for b s $GEKKO is now on Crypto.com\n",
      "@BaniSamadani\n",
      "·\n",
      "12h\n",
      "Successful for kiara_marie\n",
      "@klauda_vidhiest\n",
      "·\n",
      "12h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "12h\n",
      "Successful for Κωνσταντινος Ζαρκος\n",
      "@_kozar_\n",
      "·\n",
      "13h\n",
      "Successful for MaestroNFT\n",
      "@MaestroTKO\n",
      "·\n",
      "13h\n",
      "Successful for Crypto.com Kings.cro\n",
      "@ErikCou3993772\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n",
      "Successful for Roman $GEKKO is now on Crypto.com\n",
      "@NawabRoman\n",
      "·\n",
      "14h\n"
     ]
    }
   ],
   "source": [
    "# initialize empty lists to store scraped data\n",
    "UserTags=[]\n",
    "TimeStamps=[]\n",
    "Tweets=[]\n",
    "Replys=[]\n",
    "reTweets=[]\n",
    "Likes=[]\n",
    "\n",
    "# find all tweet articles on the page\n",
    "articles = wait.until(EC.visibility_of_all_elements_located((By.XPATH,\"//article[@data-testid='tweet']\")))\n",
    "articles = driver.find_elements(By.XPATH,\"//article[@data-testid='tweet']\")\n",
    "\n",
    "\n",
    "# loop over the articles to extract data from each tweet\n",
    "while True: \n",
    "    for article in articles:\n",
    "        # extract user handle\n",
    "        UserTag = driver.find_element(By.XPATH,\".//div[@data-testid='User-Name']\").text\n",
    "        UserTags.append(UserTag)\n",
    "\n",
    "        # extract timestamp\n",
    "        TimeStamp = driver.find_element(By.XPATH,\".//time\").get_attribute('datetime')\n",
    "        TimeStamps.append(TimeStamp)\n",
    "\n",
    "        # extract tweet text\n",
    "        Tweet = driver.find_element(By.XPATH,\".//div[@data-testid='tweetText']\").text\n",
    "        Tweets.append(Tweet)\n",
    "\n",
    "        # extract number of replies\n",
    "        Reply = driver.find_element(By.XPATH,\".//div[@data-testid='reply']\").text\n",
    "        Replys.append(Reply)\n",
    "\n",
    "        # extract number of retweets\n",
    "        reTweet = driver.find_element(By.XPATH,\".//div[@data-testid='retweet']\").text\n",
    "        reTweets.append(reTweet)\n",
    "\n",
    "        # extract number of likes\n",
    "        Like = driver.find_element(By.XPATH,\".//div[@data-testid='like']\").text\n",
    "        Likes.append(Like)\n",
    "\n",
    "        print('Successful for '+str(UserTag))\n",
    "\n",
    "        # scroll down to load more tweets\n",
    "        driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "        time.sleep(3)\n",
    "\n",
    "        # find all tweet articles again to check if there are more tweets to scrape\n",
    "        articles = driver.find_elements(By.XPATH,\"//article[@data-testid='tweet']\")\n",
    "        time.sleep(1)\n",
    "\n",
    "        k = len(Tweets) - len(list(set(Tweets)))\n",
    "        \n",
    "    if k > 5:\n",
    "        break\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a limit til which twitter identifies bot activity and the result just repeats hence I cap it when there is repetition more than 5 and check the number of tweets I was able to collect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "25\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(Tweets))\n",
    "print(len(list(set(Tweets))))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts retrieved on 2023_11_02: 37\n"
     ]
    }
   ],
   "source": [
    "# Save scraped tweets to df and csv\n",
    "df_tweets = pd.DataFrame({\"UserTags\":UserTags, \"TimeStamps\":TimeStamps, \"Tweets\":Tweets, \"Replys\":Replys, \"reTweets\":reTweets, \"Likes\":Likes})\n",
    "df_tweets.to_csv(date.today().strftime(\"%Y%m%d\")+'_tweets_selenium_@'+search_term+'.csv',index=False)\n",
    "print('Number of posts retrieved on '+date.today().strftime(\"%Y_%m_%d\")+': '+str(df_tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tweets scraped from previous days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is a daily limit, I run this code daily to collect the tweets, then import the previous days' collected tweets to merge and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 20231102_tweets_selenium_@crypto.com.csv - 37\n",
      "37\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# Define function to import past viral posts scraped\n",
    "#start date format: datetime(2023,7,18)\n",
    "dfs = ['df1','df2','df3','df4','df5','df6','df7','df8','df9','df10',\n",
    "       'df11''df12','df13','df14','df15','df16','df17','df18','df19','df20',\n",
    "       'df21']\n",
    "dfv = []\n",
    "tot_rows = 0\n",
    "def import_data(start_date,num_days,search_term): \n",
    "    start = start_date.strftime(\"%Y%m%d\")+'_tweets_selenium_@'+search_term+'.csv'\n",
    "    df = pd.read_csv(start)\n",
    "    print('Successfully imported '+start+' - '+str(df.shape[0]))\n",
    "    dfv.append(df)\n",
    "    global tot_rows\n",
    "    tot_rows += df.shape[0]\n",
    "    for i in range(1,num_days):\n",
    "        try: \n",
    "            latest_date = start_date - timedelta(days=i)\n",
    "            subsequent = latest_date.strftime('%Y%m%d')+'_tweets_selenium_@'+search_term+'.csv'\n",
    "            dfs[i] = pd.read_csv(subsequent)\n",
    "            print('Successfully imported '+subsequent+' - '+str(dfs[i].shape[0]))\n",
    "            dfv.append(dfs[i])\n",
    "            tot_rows += dfs[i].shape[0]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "import_data(datetime.today(),20,search_term)\n",
    "\n",
    "df_comb = pd.concat((dfv))\n",
    "print(df_comb.shape[0])\n",
    "print(tot_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.concat((dfv))\n",
    "df_comb[['Username', 'Handle', 'dot', 'Others']] = df_comb['UserTags'].str.split('\\n', expand=True)\n",
    "# df_comb[['Username', 'Handle', 'dot', 'Others','Others1']] = df_comb['UserTags'].str.split('\\n', expand=True)\n",
    "# df_comb[~df_comb.Others1.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>TimeStamps</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Replys</th>\n",
       "      <th>reTweets</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Naohwilliams01</td>\n",
       "      <td>2023-11-02T03:39:07.000Z</td>\n",
       "      <td>I wanna sell off my Two Tickets For DOJA CAT S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Naohwilliams01</td>\n",
       "      <td>2023-11-02T03:39:07.000Z</td>\n",
       "      <td>I wanna sell off my Two Tickets For DOJA CAT S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cryptocomcs</td>\n",
       "      <td>2023-11-02T03:12:06.000Z</td>\n",
       "      <td>Hello Abdulla! Please send us a DM at \\n@crypt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@cryptocom</td>\n",
       "      <td>2023-11-02T01:45:03.000Z</td>\n",
       "      <td>Locking in for the #BrazilGP this weekend with...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@cryptocom</td>\n",
       "      <td>2023-11-02T01:00:00.000Z</td>\n",
       "      <td>It’s your last day to receive US$50 of CRO by...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@BaniSamadani</td>\n",
       "      <td>2023-11-02T00:48:26.000Z</td>\n",
       "      <td>#airdrop #crypto #bitcoin https://twitter.com/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@BaniSamadani</td>\n",
       "      <td>2023-11-02T00:08:31.000Z</td>\n",
       "      <td>#DITEX #CRYPTO #QUEST https://x.com/ditextoken...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@GalihPradana34</td>\n",
       "      <td>2023-11-01T23:40:17.000Z</td>\n",
       "      <td>What are you waiting to join in the #giveaway ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@GalihPradana34</td>\n",
       "      <td>2023-11-01T23:35:06.000Z</td>\n",
       "      <td>PENDLE #AIRDROP LIVE (FREE)\\n\\n Binance Approv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@makayla83209</td>\n",
       "      <td>2023-11-01T23:33:38.000Z</td>\n",
       "      <td>I'm selling Los Angeles Lakers tickets for ton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@ErikCou3993772</td>\n",
       "      <td>2023-11-01T22:40:24.000Z</td>\n",
       "      <td>How do you do? This is not a drill! This is no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@cryptocom_AU</td>\n",
       "      <td>2023-11-01T21:30:01.000Z</td>\n",
       "      <td>Improving a classic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@BaniSamadani</td>\n",
       "      <td>2023-11-01T20:48:09.000Z</td>\n",
       "      <td>#Crypto #defi #bitcoin https://twitter.com/Fer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@17Wildboi</td>\n",
       "      <td>2023-11-01T19:36:55.000Z</td>\n",
       "      <td>Check out Corporation Avatar Pack - LIMITED ED...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@YNeyom</td>\n",
       "      <td>2023-11-01T19:03:39.000Z</td>\n",
       "      <td>@ https://twitter.com/toronet/status/171140954...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@YNeyom</td>\n",
       "      <td>2023-11-01T18:28:40.000Z</td>\n",
       "      <td>I joined the gasless revolution. What about yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@DutchCryptoCom</td>\n",
       "      <td>2023-11-01T17:31:52.000Z</td>\n",
       "      <td>My life changed in 2008 …</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@cryptocom</td>\n",
       "      <td>2023-11-01T17:08:21.000Z</td>\n",
       "      <td>Improving a classic</td>\n",
       "      <td>58.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@saurrabhhhh</td>\n",
       "      <td>2023-11-01T16:18:56.000Z</td>\n",
       "      <td>Memecoin is on \\n@coing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@LakersTRK</td>\n",
       "      <td>2023-11-01T15:49:31.000Z</td>\n",
       "      <td>MAÇ GÜNÜ, CLIPPERS'A SOKUŞ GÜNÜ\\n\\n Los Angel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@BaniSamadani</td>\n",
       "      <td>2023-11-01T15:33:37.000Z</td>\n",
       "      <td>#Meet48AIdolverse 2Damoon！</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@klauda_vidhiest</td>\n",
       "      <td>2023-11-01T15:06:40.000Z</td>\n",
       "      <td>Hello, I’ve got two (2) DOJA CATS tickets for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T14:59:44.000Z</td>\n",
       "      <td>Thanks for sharing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@_kozar_</td>\n",
       "      <td>2023-11-01T14:12:58.000Z</td>\n",
       "      <td>Check out Uncle Whale wearing Christmas Hat by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@MaestroTKO</td>\n",
       "      <td>2023-11-01T14:07:35.000Z</td>\n",
       "      <td>Check out Pioneer #81 by maestronft at Crypto....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@ErikCou3993772</td>\n",
       "      <td>2023-11-01T13:25:48.000Z</td>\n",
       "      <td>Hi! This is not a drill! This is not fake news...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>@NawabRoman</td>\n",
       "      <td>2023-11-01T13:08:04.000Z</td>\n",
       "      <td>$RATIO is here to stay. Keep farming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Handle                TimeStamps  \\\n",
       "0    @Naohwilliams01  2023-11-02T03:39:07.000Z   \n",
       "1    @Naohwilliams01  2023-11-02T03:39:07.000Z   \n",
       "2       @cryptocomcs  2023-11-02T03:12:06.000Z   \n",
       "3         @cryptocom  2023-11-02T01:45:03.000Z   \n",
       "4         @cryptocom  2023-11-02T01:00:00.000Z   \n",
       "5      @BaniSamadani  2023-11-02T00:48:26.000Z   \n",
       "6      @BaniSamadani  2023-11-02T00:08:31.000Z   \n",
       "7    @GalihPradana34  2023-11-01T23:40:17.000Z   \n",
       "8    @GalihPradana34  2023-11-01T23:35:06.000Z   \n",
       "9      @makayla83209  2023-11-01T23:33:38.000Z   \n",
       "10   @ErikCou3993772  2023-11-01T22:40:24.000Z   \n",
       "11     @cryptocom_AU  2023-11-01T21:30:01.000Z   \n",
       "12     @BaniSamadani  2023-11-01T20:48:09.000Z   \n",
       "13        @17Wildboi  2023-11-01T19:36:55.000Z   \n",
       "14           @YNeyom  2023-11-01T19:03:39.000Z   \n",
       "15           @YNeyom  2023-11-01T18:28:40.000Z   \n",
       "16   @DutchCryptoCom  2023-11-01T17:31:52.000Z   \n",
       "17        @cryptocom  2023-11-01T17:08:21.000Z   \n",
       "18      @saurrabhhhh  2023-11-01T16:18:56.000Z   \n",
       "19        @LakersTRK  2023-11-01T15:49:31.000Z   \n",
       "20     @BaniSamadani  2023-11-01T15:33:37.000Z   \n",
       "21  @klauda_vidhiest  2023-11-01T15:06:40.000Z   \n",
       "22       @NawabRoman  2023-11-01T14:59:44.000Z   \n",
       "23          @_kozar_  2023-11-01T14:12:58.000Z   \n",
       "24       @MaestroTKO  2023-11-01T14:07:35.000Z   \n",
       "25   @ErikCou3993772  2023-11-01T13:25:48.000Z   \n",
       "26       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "27       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "28       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "29       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "30       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "31       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "32       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "33       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "34       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "35       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "36       @NawabRoman  2023-11-01T13:08:04.000Z   \n",
       "\n",
       "                                               Tweets  Replys  reTweets  Likes  \n",
       "0   I wanna sell off my Two Tickets For DOJA CAT S...     NaN       NaN    1.0  \n",
       "1   I wanna sell off my Two Tickets For DOJA CAT S...     NaN       NaN    1.0  \n",
       "2   Hello Abdulla! Please send us a DM at \\n@crypt...     NaN       NaN    NaN  \n",
       "3   Locking in for the #BrazilGP this weekend with...    17.0      10.0   78.0  \n",
       "4    It’s your last day to receive US$50 of CRO by...    24.0      26.0   79.0  \n",
       "5   #airdrop #crypto #bitcoin https://twitter.com/...     NaN       NaN    NaN  \n",
       "6   #DITEX #CRYPTO #QUEST https://x.com/ditextoken...     NaN       NaN    NaN  \n",
       "7   What are you waiting to join in the #giveaway ...     NaN       NaN    NaN  \n",
       "8   PENDLE #AIRDROP LIVE (FREE)\\n\\n Binance Approv...     1.0       NaN    1.0  \n",
       "9   I'm selling Los Angeles Lakers tickets for ton...     NaN       NaN    NaN  \n",
       "10  How do you do? This is not a drill! This is no...     NaN       NaN    NaN  \n",
       "11                                Improving a classic     1.0       9.0   38.0  \n",
       "12  #Crypto #defi #bitcoin https://twitter.com/Fer...     NaN       NaN    NaN  \n",
       "13  Check out Corporation Avatar Pack - LIMITED ED...     NaN       NaN    NaN  \n",
       "14  @ https://twitter.com/toronet/status/171140954...     NaN       NaN    NaN  \n",
       "15  I joined the gasless revolution. What about yo...     NaN       NaN    NaN  \n",
       "16                          My life changed in 2008 …     NaN       NaN    1.0  \n",
       "17                                Improving a classic    58.0      90.0  640.0  \n",
       "18                            Memecoin is on \\n@coing     NaN       NaN    NaN  \n",
       "19   MAÇ GÜNÜ, CLIPPERS'A SOKUŞ GÜNÜ\\n\\n Los Angel...     2.0       4.0    7.0  \n",
       "20                         #Meet48AIdolverse 2Damoon！     NaN       NaN    NaN  \n",
       "21  Hello, I’ve got two (2) DOJA CATS tickets for ...     NaN       NaN    1.0  \n",
       "22                                 Thanks for sharing     NaN       NaN    NaN  \n",
       "23  Check out Uncle Whale wearing Christmas Hat by...     NaN       NaN    1.0  \n",
       "24  Check out Pioneer #81 by maestronft at Crypto....     1.0       NaN   10.0  \n",
       "25  Hi! This is not a drill! This is not fake news...     NaN       NaN    NaN  \n",
       "26               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "27               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "28               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "29               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "30               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "31               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "32               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "33               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "34               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "35               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  \n",
       "36               $RATIO is here to stay. Keep farming     NaN       NaN    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comb1 = df_comb[['Handle','TimeStamps', 'Tweets', 'Replys', 'reTweets','Likes']]\n",
    "df_comb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comb1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering tweets by \"Viral\" definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replys Stats - min: 0, max: 2\n",
      "Likes Stats - min: 0, max: 38\n",
      "Retweets Stats - min: 0, max: 9\n",
      "Percentile used for identifying viral tweets: 90.0%\n",
      "\n",
      "Viral = posts with more than 0 replies, more than 1 likes and more than 0 retweets\n",
      "\n",
      "Number of viral posts identified: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elsia/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_no_cdc = df_comb1[(df_comb1.Handle != \"@cryptocom\")&(df_comb1.Handle != \"@kris\")] #remove tweets from business account itself\n",
    "\n",
    "df_no_cdc.reTweets = df_no_cdc.reTweets.replace(',','')\n",
    "df_no_cdc.reTweets = df_no_cdc.reTweets.replace(np.nan,0, regex=True)\n",
    "df_no_cdc.Replys = df_no_cdc.Replys.replace(',','')\n",
    "df_no_cdc.Replys = df_no_cdc.Replys.replace(np.nan,0, regex=True)\n",
    "df_no_cdc.Likes = df_no_cdc.Likes.replace(',','')\n",
    "df_no_cdc.Likes = df_no_cdc.Likes.replace(np.nan,0, regex=True)\n",
    "\n",
    "df_no_cdc = df_no_cdc.astype({\"Replys\":\"int\",\"reTweets\":\"int\",\"Likes\":\"int\"})\n",
    "\n",
    "#Define quartile \n",
    "pct = 0.9\n",
    "\n",
    "#Define threadholds\n",
    "replys_threshold = df_no_cdc.Replys.quantile(pct)\n",
    "likes_threshold = df_no_cdc.Likes.quantile(pct)\n",
    "retweet_threshold = df_no_cdc.reTweets.quantile(pct)\n",
    "print(\n",
    "    \n",
    "    'Replys Stats - min: '+str(df_no_cdc.Replys.min())+', max: '+str(df_no_cdc.Replys.max())+\n",
    "    '\\nLikes Stats - min: '+str(df_no_cdc.Likes.min())+', max: '+str(df_no_cdc.Likes.max())+\n",
    "    '\\nRetweets Stats - min: '+str(df_no_cdc.reTweets.min())+', max: '+str(df_no_cdc.reTweets.max())+\n",
    "    '\\nPercentile used for identifying viral tweets: '+str(pct*100)+'%'+\n",
    "    '\\n\\nViral = posts with more than '+str(int(replys_threshold))+' replies, more than '+str(int(likes_threshold))+' likes and more than '+str(int(retweet_threshold))+' retweets'\n",
    "    )\n",
    "\n",
    "#Filter by comments and upvote count thresholds\n",
    "df_no_cdc = df_no_cdc[(df_no_cdc.Replys>=replys_threshold)&(df_no_cdc.Likes>=likes_threshold)&(df_no_cdc.reTweets>=retweet_threshold)]\n",
    "df_no_cdc_no_dup = df_no_cdc.drop_duplicates(subset=['Tweets'], keep='first')\n",
    "df_no_cdc_no_dup.to_csv(date.today().strftime(\"%Y%m%d\")+'_tweets_selenium_@'+search_term+'_viral.csv',index=False)\n",
    "print('\\nNumber of viral posts identified: '+str(df_no_cdc_no_dup.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df = pd.read_csv(date.today().strftime(\"%Y%m%d\")+'_tweets_selenium_@'+search_term+'_viral.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarise using OpenAI API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets summarised: 4\n",
      "\n",
      " Users are satisfied with the free airdrop of $PENDLE on Binance and the availability of the Pioneer #81 NFT by maestronft on Crypto.com. They are also satisfied with the Los Angeles Clippers' upcoming match at the Crypto com Arena.\n",
      "\n",
      "Users want more free airdrops and NFTs from Crypto.com. They also want more matches from the Los Angeles Clippers.\n"
     ]
    }
   ],
   "source": [
    "# Use openai API to summarise the dataset\n",
    "\n",
    "#Import library\n",
    "import openai\n",
    "\n",
    "def summarize_corpus(corpus):\n",
    "    # Set up OpenAI API credentials\n",
    "    openai.api_key = 'xx' #replace with own key\n",
    "    \n",
    "    # Provide the prompt and settings for the API call\n",
    "    prompt = 'Context: The text is a compilation of tweets. Act as a market analyst, summarise what users are satisfied about and unsatisfied about and provide details about what users want : ' + corpus.to_json()\n",
    "    # prompt = 'Context: The text is a compilation of tweets that tag @crytocom. Act as a market analyst, summarise what users are satisfied about and unsatisfied about and provide details about what users want : ' + corpus.to_json()\n",
    "    max_tokens = 500  # Maximum number of tokens for the summary\n",
    "\n",
    "    # Call the OpenAI API to generate the summary\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.2,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Extract the generated summary from the API response\n",
    "    summary = response.choices[0].text.strip()\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Use the defined function above\n",
    "corpus = df.Tweets\n",
    "summary = summarize_corpus(corpus)\n",
    "print(\"Number of tweets summarised:\",corpus.shape[0])\n",
    "print('\\n',summary) #copy output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
